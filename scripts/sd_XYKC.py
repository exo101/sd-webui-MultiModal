import os
import torch
from modules import devices
import gradio as gr
import numpy as np
import datetime
from pathlib import Path
from modules import script_callbacks
import webbrowser
import subprocess
import sys
import time

# æ·»åŠ scriptsç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œç¡®ä¿æ¨¡å—å¯ä»¥è¢«æ­£ç¡®åŠ è½½
scripts_dir = Path(__file__).parent
if str(scripts_dir) is not None and str(scripts_dir) not in sys.path:
    sys.path.append(str(scripts_dir))

def import_modules():
    """å°è¯•å¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—ï¼Œå¹¶è¿”å›åŒ…å«è¿™äº›æ¨¡å—çš„å‘½åç©ºé—´å¯¹è±¡"""
    def _import_and_register_modules():
        # ç¡®ä¿å½“å‰è„šæœ¬ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
        script_dir = str(scripts_dir)
        if script_dir not in sys.path:
            sys.path.insert(0, script_dir)
            
        try: from prompt_templates import create_prompt_template_ui
        except ImportError: create_prompt_template_ui = None
        
        try: from quick_description import create_quick_description
        except ImportError: create_quick_description = None
        
        try: from video_frame_extractor import create_video_frame_extractor
        except ImportError: create_video_frame_extractor = None
        
        try: from image_matting import create_image_matting_module
        except ImportError: create_image_matting_module = None
        
        try: from image_management import create_image_management_module
        except ImportError: create_image_management_module = None
        
        try: from tag_management import create_tag_management_module
        except ImportError: create_tag_management_module = None
        
        try: from announcement import create_announcement_module
        except ImportError: create_announcement_module = None
        
        try: from latent_sync_ui import create_latent_sync_ui
        except ImportError: create_latent_sync_ui = None
        
        try: from index_tts_ui import create_index_tts_ui, INDEX_TTS_AVAILABLE
        except ImportError: 
            create_index_tts_ui = None
            INDEX_TTS_AVAILABLE = False
        
        try: from flux_kontext_ui import create_flux_kontext_ui, FLUX_KONTEXT_AVAILABLE
        except ImportError: 
            create_flux_kontext_ui = None
            FLUX_KONTEXT_AVAILABLE = False
            
        try: 
            from cleaner_ui import create_cleaner_module, CLEANER_AVAILABLE
        except ImportError: 
            create_cleaner_module = None
            CLEANER_AVAILABLE = False
            
        try: 
            from qwen_image_ui import create_qwen_image_ui, QWEN_IMAGE_MODULE_AVAILABLE
        except ImportError: 
            create_qwen_image_ui = None
            QWEN_IMAGE_MODULE_AVAILABLE = False
            
        try: 
            from segment_anything_ui import create_sam_ui, SAM_AVAILABLE
        except ImportError: 
            create_sam_ui = None
            SAM_AVAILABLE = False
        
        # è¿”å›å‘½åç©ºé—´å¯¹è±¡
        import types
        namespace = types.SimpleNamespace()
        namespace.create_prompt_template_ui = create_prompt_template_ui
        namespace.create_quick_description = create_quick_description
        namespace.create_video_frame_extractor = create_video_frame_extractor
        namespace.create_image_matting_module = create_image_matting_module
        namespace.create_image_management_module = create_image_management_module
        namespace.create_tag_management_module = create_tag_management_module
        namespace.create_announcement_module = create_announcement_module
        namespace.create_latent_sync_ui = create_latent_sync_ui
        namespace.create_index_tts_ui = create_index_tts_ui
        namespace.INDEX_TTS_AVAILABLE = INDEX_TTS_AVAILABLE
        namespace.create_flux_kontext_ui = create_flux_kontext_ui
        namespace.FLUX_KONTEXT_AVAILABLE = FLUX_KONTEXT_AVAILABLE
        namespace.create_cleaner_module = create_cleaner_module
        namespace.CLEANER_AVAILABLE = CLEANER_AVAILABLE
        namespace.create_qwen_image_ui = create_qwen_image_ui
        namespace.QWEN_IMAGE_MODULE_AVAILABLE = QWEN_IMAGE_MODULE_AVAILABLE
        namespace.create_sam_ui = create_sam_ui
        namespace.SAM_AVAILABLE = SAM_AVAILABLE
        
        return namespace
    
    return _import_and_register_modules()

# å°è¯•å¯¼å…¥æ‰€æœ‰æ¨¡å—
imported_modules = import_modules()

# å°†å¯¼å…¥çš„æ¨¡å—èµ‹å€¼ç»™å˜é‡ï¼Œæ–¹ä¾¿åœ¨åç»­ä»£ç ä¸­ä½¿ç”¨
create_prompt_template_ui = imported_modules.create_prompt_template_ui
create_quick_description = imported_modules.create_quick_description
create_video_frame_extractor = imported_modules.create_video_frame_extractor
create_image_matting_module = imported_modules.create_image_matting_module
create_image_management_module = imported_modules.create_image_management_module
create_tag_management_module = imported_modules.create_tag_management_module
create_announcement_module = imported_modules.create_announcement_module
create_latent_sync_ui = imported_modules.create_latent_sync_ui
create_index_tts_ui = imported_modules.create_index_tts_ui
INDEX_TTS_AVAILABLE = imported_modules.INDEX_TTS_AVAILABLE

create_sam_segmentation = imported_modules.create_sam_ui
SAM_AVAILABLE = imported_modules.SAM_AVAILABLE

create_flux_kontext_ui = imported_modules.create_flux_kontext_ui
FLUX_KONTEXT_AVAILABLE = imported_modules.FLUX_KONTEXT_AVAILABLE

# æ·»åŠ  cleaner æ¨¡å—å˜é‡èµ‹å€¼
create_cleaner_module = imported_modules.create_cleaner_module
CLEANER_AVAILABLE = imported_modules.CLEANER_AVAILABLE


# æ·»åŠ  qwen_image_ui æ¨¡å—å˜é‡èµ‹å€¼
create_qwen_image_ui = imported_modules.create_qwen_image_ui
QWEN_IMAGE_MODULE_AVAILABLE = imported_modules.QWEN_IMAGE_MODULE_AVAILABLE

# ç¡®ä¿ SAM å’Œ Cleaner æ¨¡å—å˜é‡æ­£ç¡®èµ‹å€¼
create_sam_ui = imported_modules.create_sam_ui
SAM_AVAILABLE = imported_modules.SAM_AVAILABLE
create_cleaner_module = imported_modules.create_cleaner_module
CLEANER_AVAILABLE = imported_modules.CLEANER_AVAILABLE

current_dir = os.path.abspath(os.getcwd())
# ä¿®æ”¹ï¼šä¸å†ä½¿ç”¨æ’ä»¶è‡ªå¸¦çš„Pythonè§£é‡Šå™¨ï¼Œè€Œæ˜¯ä½¿ç”¨ç³»ç»ŸPython
# python_interpreter = os.path.join(current_dir, "extensions\\sd-webui-XYKC\\XYKC_AI\\python.exe")
python_interpreter = sys.executable
# ä¿®æ”¹ï¼šä½¿ç”¨æ­£ç¡®çš„MultiModalæ‰©å±•è·¯å¾„
ollama_api_script_path = os.path.join(current_dir, "extensions\\sd-webui-MultiModal\\XYKC_AI\\XYKC_AI_PyScripts\\ollama_api.py")

# è§„èŒƒåŒ–è·¯å¾„
python_interpreter = os.path.normpath(python_interpreter)
ollama_api_script_path = os.path.abspath(ollama_api_script_path)

class ModelProcessor:
    """æ¨¡å‹å¤„ç†å™¨ç±»,å°è£…æ¨¡å‹ç›¸å…³æ“ä½œ"""
    @staticmethod
    def build_args(mode, model_name, user_input, file_path=None):
        """æ„å»ºå‘½ä»¤è¡Œå‚æ•°"""
        args = [mode, model_name, user_input]
        if file_path:
            args.append(file_path)
        return args
        
    @staticmethod
    def run_model(args, script_path):
        """è¿è¡Œæ¨¡å‹å¹¶è·å–è¾“å‡º"""
        full_cmd = [python_interpreter, script_path] + args
        result = subprocess.run(full_cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            error_msg = result.stderr if result.stderr else result.stdout
            return f"æ¨¡å‹æ‰§è¡Œå¤±è´¥: {error_msg}"
            
        return result.stdout

    @staticmethod
    def process_image(model_name, image_path, script_path, user_input, is_batch=False, save_dir=None):
        """å¤„ç†å•å¼ æˆ–æ‰¹é‡å›¾ç‰‡"""
        args = ModelProcessor.build_args("vision", model_name, user_input, image_path)
        result = ModelProcessor.run_model(args, script_path)
        
        if is_batch and save_dir:
            save_path = os.path.join(save_dir, os.path.splitext(os.path.basename(image_path))[0]) + ".txt"
            FileHandler.save_text(result, save_path)
            return f"å·²ä¿å­˜: {save_path}"
            
        return result

    @staticmethod
    def process_text(model_name, script_path, user_input):
        """å¤„ç†çº¯æ–‡æœ¬å¯¹è¯"""
        args = ModelProcessor.build_args("text", model_name, user_input)
        return ModelProcessor.run_model(args, script_path)

class FileHandler:
    """æ–‡ä»¶å¤„ç†ç±»"""
    @staticmethod
    def save_text(content, path):
        """ä¿å­˜æ–‡æœ¬å†…å®¹åˆ°æ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
            
    @staticmethod
    def save_chat_history(chat_history):
        """ä¿å­˜èŠå¤©è®°å½•"""
        save_dir = os.path.join(os.path.dirname(__file__), "chat_history")
        os.makedirs(save_dir, exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(save_dir, f"chat_history_{timestamp}.txt")
        
        with open(filename, "w", encoding='utf-8') as f:
            for human_message, ai_message in chat_history:
                f.write(f"ç”¨æˆ·: {human_message}\n")
                f.write(f"AI: {ai_message}\n\n")
        return f"èŠå¤©è®°å½•å·²ä¿å­˜åˆ°: {filename}"

class UIHelper:
    """UIè¾…åŠ©ç±»"""
    @staticmethod
    def get_upload_visibility(is_single):
        """è·å–ä¸Šä¼ ç»„ä»¶å¯è§æ€§"""
        return [is_single, not is_single]  # [image, multi_image]

    @staticmethod
    def switch_upload(upload_method):
        """åˆ‡æ¢ä¸Šä¼ æ–¹å¼"""
        is_single = upload_method == "single"
        visibilities = UIHelper.get_upload_visibility(is_single)
        save_path_info = "å·²é”å®š æ— éœ€å¡«å†™" if is_single else "ç»“æœä¿å­˜è·¯å¾„"
        
        return (*[gr.update(visible=v) for v in visibilities],
                gr.update(info=save_path_info, interactive=not is_single))

    @staticmethod
    def get_model_updates(model_type):
        is_vision = model_type == "vision"
        return [
            gr.update(interactive=not is_vision),  # language_model
            gr.update(interactive=is_vision),      # vision_model
            gr.update(visible=is_vision),          # image_components
            gr.update(label="AI èŠå¤©")             # chat_history labelï¼ˆå¯é€‰ï¼‰
        ]

class ChatProcessor:
    """èŠå¤©å¤„ç†ç±»"""
    @staticmethod
    def process_model_task(model_name, message, upload_method, script_path, chat_history,
                          input_data, batch_save_path=None, model_type="vision"):
        """å¤„ç†æ¨¡å‹ä»»åŠ¡"""
        if not model_name:
            chat_history.append(("æ¨¡å‹", "æ¨¡å‹ä¸èƒ½ä¸ºç©º"))
            return chat_history

        if model_type == "vision":
            if not input_data:
                chat_history.append(("é”™è¯¯", "æœªé€‰æ‹©å›¾ç‰‡æ–‡ä»¶"))
                return chat_history
                
            if upload_method == "single":
                input_path = input_data if isinstance(input_data, str) else input_data.name
                output = ModelProcessor.process_image(model_name, input_path, script_path, message)
                user_message = f"{model_name}:{message} ![]({input_path})"
                chat_history.append((user_message, output))
                
            elif upload_method == "batch" and os.path.isdir(batch_save_path):
                results = []
                for file_path in [f.name for f in input_data]:
                    result = ModelProcessor.process_image(model_name, file_path, script_path, message, 
                                                        True, batch_save_path)
                    results.append(result)
                chat_history.append((f"{model_name}:æ‰¹é‡ä»»åŠ¡", "\n".join(results)))
        else:
            # å¤„ç†è¯­è¨€æ¨¡å‹å¯¹è¯
            output = ModelProcessor.process_text(model_name, script_path, message)
            chat_history.append((message, output))
            
        return chat_history

    @staticmethod
    def extract_prompt(chat_history):
        """æå–æç¤ºè¯"""
        if not chat_history:
            return ""
        
        for msg in reversed(chat_history):
            user_msg, ai_msg = msg
            if isinstance(user_msg, str) and not user_msg.startswith("![]"):
                return user_msg
            if isinstance(ai_msg, str):
                return ai_msg
        return ""

    @staticmethod
    def extract_image_and_prompt(chat_history):
        """æå–å›¾ç‰‡è·¯å¾„å’Œæç¤ºè¯"""
        for msg in reversed(chat_history):
            if isinstance(msg[0], str) and msg[0].startswith("![]"):
                start_idx = msg[0].find("(") + 1
                end_idx = msg[0].find(")")
                if start_idx > 0 and end_idx > start_idx:
                    return msg[0][start_idx:end_idx], msg[1] if isinstance(msg[1], str) else ""
        return None, ""

# å®šä¹‰æ”¯æŒçš„è§†è§‰æ¨¡å‹
vision_model_names = [
    "qwen2.5vl:latest",
    "qwen2.5vl:3b",    
    "llama3.2-vision:latest",
]

# å®šä¹‰æ”¯æŒçš„è¯­è¨€æ¨¡å‹
language_model_names = [
    "qwen3:latest",
    "qwen3:1.7b",
    "deepseek-r1:8b",
]

# æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
image_format = [".png", ".jpg", ".jpeg", ".webp", ".bmp", ".tiff"]

def open_url():
    webbrowser.open("https://help.aliyun.com/zh/dashscope/developer-reference/acquisition-and-configuration-of-api-key/")

def show_qwen_api_box(model):
    return (gr.update(visible=False, open=False),
            gr.update(label=f'å’Œ {model} èŠå¤©'))

def get_script_path(model_name):
    return ollama_api_script_path

def chat(message, chat_history, vision_model, language_model, model_type, upload_method, batch_save_path,
         image_input, multi_images_input):
    # æ·»åŠ å¤„ç†çŠ¶æ€åé¦ˆ
    if "[å¤„ç†ä¸­ï¼Œè¯·ç¨å€™" in message:
        # è¿™æ˜¯ä¸€ä¸ªå¿«æ·æè¿°æŒ‰é’®çš„ç‚¹å‡»ï¼Œä¸éœ€è¦ç‰¹æ®Šå¤„ç†
        pass
    elif "stable diffusion" in message.lower() or "sd prompt" in message.lower():
        # æ·»åŠ å¤„ç†æç¤ºåˆ°èŠå¤©å†å²
        chat_history.append(("ç”¨æˆ·", f"[å¤„ç†ä¸­] æ­£åœ¨ç”ŸæˆStable Diffusionæç¤ºè¯ï¼Œè¯·ç¨å€™..."))
    
    script_path = get_script_path(vision_model if model_type == "vision" else language_model)
    model_name = vision_model if model_type == "vision" else language_model
    input_data = image_input if upload_method == "single" else multi_images_input
    
    chat_history = ChatProcessor.process_model_task(
        model_name, message, upload_method, script_path, chat_history,
        input_data, batch_save_path, model_type
    )
    
    return "", chat_history, image_input

def XYKC_tab():
    with gr.Blocks(analytics_enabled=False) as ui:
        with gr.Tabs():
            # é‡è¦å…¬å‘Šæ ‡ç­¾é¡µ
            with gr.TabItem("1èµ„æºæ±‡æ€»"):
                # ä½¿ç”¨å»¶è¿Ÿæ¸²æŸ“é¿å…å‡ºç°ç©ºæ¨¡å—é—®é¢˜   
                announcement_ui = create_announcement_module()
                if "markdown_content" in announcement_ui:
                    announcement_ui["markdown_content"]
            
            
            # å›¾åƒè¯†åˆ«ä¸è¯­è¨€äº¤äº’æ ‡ç­¾é¡µ
            with gr.TabItem("2å›¾åƒè¯†åˆ«ä¸è¯­è¨€äº¤äº’"):
                with gr.Row():
                    # å·¦ä¾§åŒºåŸŸï¼šæ ‡ç­¾ç®¡ç†ã€å›¾åƒè¯†åˆ«ä¸è¯­è¨€äº¤äº’ã€æ¨¡å‹é€‰æ‹©ä½œä¸ºä¸€ä¸ªæ•´ä½“
                    with gr.Column(scale=1):
                        # æ ‡ç­¾ç®¡ç†æ¨¡å—
                        tag_management_components = create_tag_management_module()
                        tag_management_components["folder_path"].elem_classes = ["xykc-accordion"]
                        
                        # å›¾åƒç®¡ç†æ¨¡å—
                        try:
                            image_management_ui = create_image_management_module()
                            if image_management_ui:
                                with gr.Box():
                                    if "dir_input" in image_management_ui:
                                        image_management_ui["dir_input"]
                                    if "load_dir_btn" in image_management_ui:
                                        image_management_ui["load_dir_btn"]
                                    if "gallery" in image_management_ui:
                                        image_management_ui["gallery"]
                        except Exception as e:
                            print(f"å›¾åƒç®¡ç†æ¨¡å—åŠ è½½å¤±è´¥: {e}")
                        
                        # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
                        with gr.Group():
                            model_type = gr.Radio(
                                [("å›¾åƒè¯†åˆ«", "vision"), ("è¯­è¨€äº¤äº’", "text")],
                                value="vision",
                                label="æ¨¡å‹ç±»å‹",
                                interactive=True,
                                info="åªæœ‰å›¾åƒè¯†åˆ«æ¨¡å‹æ‰å¯ä»¥ä¸å›¾ç‰‡è¿›è¡Œäº¤äº’å’Œæ‰¹é‡æ“ä½œ"
                            )
                            
                            gr.Markdown("ğŸ“Œ **æ¨¡å‹é€‰æ‹©å»ºè®®**ï¼š8GBæ˜¾å­˜é€‰æ‹©1.7Bæˆ–3Bæ¨¡å‹è·å¾—æ›´å¿«å“åº”é€Ÿåº¦ï¼Œ16GBæ˜¾å­˜å¯é€‰æ‹©latestæˆ–7Bæ¨¡å‹")
                            
                            vision_model = gr.Dropdown(
                                label="è§†è§‰æ¨¡å‹",
                                choices=vision_model_names,
                                value=vision_model_names[0] if vision_model_names else None,
                                interactive=True,
                                info="é€‰æ‹©è§†è§‰æ¨¡å‹",
                                scale=2,
                                elem_classes="larger-text",
                                container=True
                            )
                            
                            language_model = gr.Dropdown(
                                label="è¯­è¨€æ¨¡å‹",
                                choices=language_model_names,
                                value=language_model_names[0] if language_model_names else None,
                                interactive=False,
                                info="é€‰æ‹©è¯­è¨€æ¨¡å‹",
                                scale=2,
                                elem_classes="larger-text",
                                container=True
                            )
                        
                        # å›¾åƒè¯†åˆ«ä¸è¯­è¨€äº¤äº’åŒºåŸŸ
                        with gr.Group():
                            gr.Markdown("### å›¾åƒè¯†åˆ«ä¸è¯­è¨€äº¤äº’")
                            with gr.Row(visible=True) as image_components:
                                upload_method = gr.Radio(
                                    [("å•å¼ å›¾ç‰‡", "single"), ("æ‰¹é‡å›¾ç‰‡", "batch")],
                                    value="single",
                                    label="ä¸Šä¼ æ–¹å¼",
                                    interactive=True,
                                    scale=2,
                                    elem_classes="larger-text",
                                    container=True
                                )
                                batch_save_path = gr.Textbox(
                                    label="ç»“æœä¿å­˜è·¯å¾„",                       
                                    interactive=False,
                                    info="å·²é”å®š æ— éœ€å¡«å†™",
                                    scale=2,
                                    elem_classes="larger-text",
                                    container=True
                                )
                            
                            with gr.Box(visible=True) as image_container:
                                image_input = gr.Image(
                                    type="filepath",
                                    label="å•å¼ å›¾ç‰‡è¾“å…¥",
                                    visible=True, 
                                    height=300,
                                    scale=1,
                                    min_width=300,
                                    show_label=True,
                                    container=True
                                )
                                multi_images_input = gr.Files(
                                    type="filepath",
                                    label="å¤šå¼ å›¾ç‰‡è¾“å…¥",
                                    visible=False,
                                    height=300,
                                    scale=1,
                                    min_width=300,
                                    file_count="multiple",
                                    file_types=image_format
                                )
                    
                    # å³ä¾§åŒºåŸŸï¼šå…³é”®è¯è¾…åŠ©æ¨¡æ¿å’ŒèŠå¤©åŒºåŸŸä½œä¸ºä¸€ä¸ªæ•´ä½“
                    with gr.Column(scale=1):
                        # å…³é”®è¯è¾…åŠ©æ¨¡æ¿åŒºåŸŸ
                        with gr.Accordion("å…³é”®è¯è¾…åŠ©æ¨¡æ¿", open=False):
                            template_ui = create_prompt_template_ui()
                            with gr.Row():
                                with gr.Column():
                                    template_ui["expression_template"]
                                with gr.Column():
                                    template_ui["story_template"]
                                with gr.Column():
                                    template_ui["shot_template"]
                        
                        # èŠå¤©åŒºåŸŸ
                        chat_history = gr.Chatbot(
                            elem_id="chatbot", 
                            label="èŠå¤©è®°å½•", 
                            height=300,
                            render=True
                        )
                        chat_message = gr.Textbox(
                            show_label=False,
                            placeholder="è¾“å…¥æ¶ˆæ¯æˆ–ä¸Šä¼ å›¾ç‰‡",
                            container=True,
                            scale=1,
                            min_width=300,
                            lines=3
                        )
                        with gr.Row(equal_height=True):
                            submit_button = gr.Button(
                                "å‘é€",
                                size="lg",
                                variant="primary",
                                elem_classes="orange-button",
                                scale=2
                            )
                            clear_button = gr.Button(
                                "æ¸…ç©ºèŠå¤©",
                                size="lg", 
                                variant="primary",
                                elem_classes="orange-button",
                                scale=2
                            )
                            save_button = gr.Button(
                                "ä¿å­˜èŠå¤©è®°å½•",
                                size="lg",
                                variant="primary",
                                elem_classes="orange-button",
                                scale=2
                            )

                        # å¿«æ·æè¿°åŒºåŸŸ
                        with gr.Group():
                            # åˆ›å»ºå¹¶æ·»åŠ å¿«æ·æè¿°æŒ‰é’®
                            quick_description_buttons = create_quick_description(chat_message)
                            
                            # å°†å¿«æ·æè¿°æŒ‰é’®ç‚¹å‡»äº‹ä»¶ç»‘å®šåˆ°èŠå¤©è¾“å…¥æ¡†

                chat_inputs = [
                    chat_message, chat_history, vision_model, language_model,
                    model_type, upload_method, batch_save_path,
                    image_input, multi_images_input
                ]
                chat_outputs = [chat_message, chat_history, image_input]

                chat_message.submit(chat, inputs=chat_inputs, outputs=chat_outputs)
                submit_button.click(chat, inputs=chat_inputs, outputs=chat_outputs)
                clear_button.click(lambda: [[], ""], outputs=[chat_history, chat_message])
                save_button.click(
                    FileHandler.save_chat_history,
                    inputs=[chat_history],
                    outputs=[gr.Textbox(visible=True, value="", label="ä¿å­˜çŠ¶æ€")]
                )
                # æ¨¡å‹ç±»å‹åˆ‡æ¢äº‹ä»¶
                model_type.change(
                    fn=UIHelper.get_model_updates,
                    inputs=[model_type],
                    outputs=[
                        language_model,     # è¾“å‡º1: æ§åˆ¶è¯­è¨€æ¨¡å‹æ˜¯å¦å¯äº¤äº’
                        vision_model,       # è¾“å‡º2: æ§åˆ¶è§†è§‰æ¨¡å‹æ˜¯å¦å¯äº¤äº’
                        image_components,   # è¾“å‡º3: æ§åˆ¶å›¾ç‰‡ä¸Šä¼ åŒºåŸŸæ˜¯å¦æ˜¾ç¤º
                        chat_history        # è¾“å‡º4: æ›´æ–°èŠå¤©è®°å½•æ ‡ç­¾åï¼ˆå¯é€‰ï¼‰
                    ]
                )
                upload_method.change(
                    UIHelper.switch_upload,
                    inputs=[upload_method],
                    outputs=[image_input, multi_images_input, batch_save_path]
                )

                ui.load(lambda: "single", outputs=[upload_method])
          
            
            # å›¾åƒåˆ†å‰²/å›¾åƒæŠ å›¾/å›¾åƒæ¸…ç†æ ‡ç­¾é¡µ
            with gr.TabItem("3.å›¾åƒåˆ†å‰²/å›¾åƒæŠ å›¾/å›¾åƒæ¸…ç†"):
                with gr.Tabs():
                    with gr.TabItem("æ™ºèƒ½æŠ å›¾"):
                        # ç®€åŒ–è°ƒç”¨æ–¹å¼å¹¶ç»Ÿä¸€ç»“æ„
                        try:
                            create_image_matting_module()
                        except Exception as e:
                            gr.Markdown(f"æ™ºèƒ½æŠ å›¾æ¨¡å—åŠ è½½å¤±è´¥ï¼š{e}")
                    
                    with gr.TabItem("å›¾åƒåˆ†å‰²"):
                        # æ£€æŸ¥å¹¶æ˜¾ç¤ºå›¾åƒåˆ†å‰²æ¨¡å—
                        if SAM_AVAILABLE and create_sam_segmentation is not None:
                            try:
                                sam_ui_components = create_sam_segmentation()
                            except Exception as e:
                                with gr.Group():
                                    gr.Markdown("## å›¾åƒåˆ†å‰²")
                                    gr.Markdown(f"å›¾åƒåˆ†å‰²æ¨¡å—åŠ è½½æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}")
                                    gr.Markdown("è¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºä»¥è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
                                import traceback
                                traceback.print_exc()
                        else:
                            gr.Markdown("å›¾åƒåˆ†å‰²æ¨¡å—ä¸å¯ç”¨ã€‚è¯·ç¡®ä¿å·²å®‰è£…segment-anythingåº“ã€‚")
                    
                    with gr.TabItem("å›¾åƒæ¸…ç†"):
                        # æ£€æŸ¥å¹¶æ˜¾ç¤ºå›¾åƒæ¸…ç†æ¨¡å—
                        if CLEANER_AVAILABLE and create_cleaner_module is not None:
                            try:
                                cleaner_ui_components = create_cleaner_module()
                            except Exception as e:
                                with gr.Group():
                                    gr.Markdown("## å›¾åƒæ¸…ç†")
                                    gr.Markdown(f"å›¾åƒæ¸…ç†æ¨¡å—åŠ è½½æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}")
                                    gr.Markdown("è¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºä»¥è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
                                import traceback
                                traceback.print_exc()
                        else:
                            gr.Markdown("å›¾åƒæ¸…ç†æ¨¡å—ä¸å¯ç”¨ã€‚è¯·ç¡®ä¿å·²å®‰è£…litelamaåº“ã€‚")
            
            # è§†é¢‘å…³é”®å¸§æå–æ ‡ç­¾é¡µ
            with gr.TabItem("4.è§†é¢‘å…³é”®å¸§æå–"):
                # åˆ›å»ºå¹¶æ·»åŠ è§†é¢‘åˆ†å¸§ç»„ä»¶
                video_frame_components = create_video_frame_extractor()                   

                # å°†è§†é¢‘åˆ†å¸§ç»„ä»¶è§£åŒ…
                video_input = video_frame_components["video_input"]
                frame_output = video_frame_components["frame_output"]
                frame_quality = video_frame_components["frame_quality"]
                frame_mode = video_frame_components["frame_mode"]
                frame_preview = video_frame_components["frame_preview"]
                extract_video_frames = video_frame_components["extract_video_frames"]
                
                # ç»‘å®šæŒ‰é’®ç‚¹å‡»äº‹ä»¶
                extract_button = gr.Button("æå–å…³é”®å¸§")
                extract_button.click(
                    fn=extract_video_frames,
                    inputs=[video_input, frame_output, frame_quality, frame_mode],
                    outputs=[gr.File(label="æå–çš„å¸§æ–‡ä»¶"), frame_preview]
                )
            
            # æ•°å­—äººè§†é¢‘ç”Ÿæˆæ ‡ç­¾é¡µ
            with gr.TabItem("5.æ•°å­—äººå¯¹å£å‹ç”Ÿæˆ"):
                # åˆ›å»ºå¹¶æ·»åŠ æ•°å­—äººè§†é¢‘ç”ŸæˆåŠŸèƒ½
                latent_sync_components = create_latent_sync_ui()
                
                # å°†ç»„ä»¶è§£åŒ…ä»¥ä¾›å¼•ç”¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                latent_video_input = latent_sync_components["video_input"]
                latent_audio_input = latent_sync_components["audio_input"]
                latent_guidance_scale = latent_sync_components["guidance_scale"]
                latent_inference_steps = latent_sync_components["inference_steps"]
                latent_seed = latent_sync_components["seed"]
                latent_process_btn = latent_sync_components["process_btn"]
                latent_video_output = latent_sync_components["video_output"]

            # Index-TTSè¯­éŸ³åˆæˆæ ‡ç­¾é¡µï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'INDEX_TTS_AVAILABLE' in globals() and INDEX_TTS_AVAILABLE:
                with gr.TabItem("6.Index-TTSè¯­éŸ³åˆæˆ"):
                    try:
                        # åˆ›å»ºå¹¶æ·»åŠ Index-TTSåŠŸèƒ½
                        index_tts_components = create_index_tts_ui()
                    except Exception as e:
                        gr.Markdown(f"Index-TTSæ¨¡å—åˆå§‹åŒ–é”™è¯¯: {e}")
                        import traceback
                        traceback.print_exc()
            elif 'INDEX_TTS_AVAILABLE' in globals() and not INDEX_TTS_AVAILABLE:
                with gr.TabItem("6.Index-TTSè¯­éŸ³åˆæˆ"):
                    gr.Markdown("Index-TTSæ¨¡å—å½“å‰ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯å› ä¸ºç¼ºå°‘æ¨¡å‹æ–‡ä»¶æˆ–ä¾èµ–é¡¹ã€‚")

            # FLUX.1-Kontextæ ‡ç­¾é¡µï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'FLUX_KONTEXT_AVAILABLE' in globals() and FLUX_KONTEXT_AVAILABLE:
                with gr.TabItem("7.FLUX.1-Kontextå›¾åƒç¼–è¾‘"):
                    try:
                        # ç›´æ¥åˆ›å»ºFLUX.1-Kontext UIç»„ä»¶
                        flux_kontext_components = create_flux_kontext_ui()
                        
                        # å¦‚æœç»„ä»¶åˆ›å»ºæˆåŠŸï¼Œå®ƒä»¬å·²ç»åœ¨create_flux_kontext_uiå‡½æ•°ä¸­è¢«æ­£ç¡®åˆ›å»ºå’Œæ˜¾ç¤º
                        # ä¸éœ€è¦é¢å¤–çš„å¤„ç†
                        if not flux_kontext_components:
                            gr.Markdown("FLUX.1-Kontextæ¨¡å—åŠ è½½å¤±è´¥")
                    except Exception as e:
                        gr.Markdown(f"FLUX.1-Kontextæ¨¡å—åˆå§‹åŒ–é”™è¯¯: {e}")
 
            # æ·»åŠ  Qwen Image æ ‡ç­¾é¡µï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'QWEN_IMAGE_MODULE_AVAILABLE' in globals() and QWEN_IMAGE_MODULE_AVAILABLE:
                with gr.TabItem("8.Qwen Imageå›¾åƒç”Ÿæˆ"):
                    try:
                        # åˆ›å»º Qwen Image UI ç»„ä»¶
                        qwen_image_components = create_qwen_image_ui()
                        
                        # ç»„ä»¶å·²ç»è‡ªåŠ¨æ˜¾ç¤ºï¼Œæ— éœ€é¢å¤–å¤„ç†
                        if not qwen_image_components:
                            gr.Markdown("Qwen Imageæ¨¡å—åŠ è½½å¤±è´¥")
                    except Exception as e:
                        gr.Markdown(f"Qwen Imageæ¨¡å—åˆå§‹åŒ–é”™è¯¯: {e}")
                        import traceback
                        traceback.print_exc()
            elif 'QWEN_IMAGE_MODULE_AVAILABLE' in globals() and not QWEN_IMAGE_MODULE_AVAILABLE:
                with gr.TabItem("8.Qwen Imageå›¾åƒç”Ÿæˆ"):
                    gr.Markdown("Qwen Imageæ¨¡å—å½“å‰ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯å› ä¸ºç¼ºå°‘æ¨¡å‹æ–‡ä»¶æˆ–ä¾èµ–é¡¹ã€‚")
            
            # ç§»é™¤åƒé—®å›¾åƒç”Ÿæˆæ ‡ç­¾é¡µ
            
        
    return [(ui, "å¤šæ¨¡æ€æ’ä»¶12", "XYKC_vision_tab")]

script_callbacks.on_ui_tabs(XYKC_tab)

import modules.scripts as scripts
import gradio as gr
from modules import script_callbacks

# åœ¨WebUIå¯åŠ¨æ—¶åœ¨åå°æ—¥å¿—ä¸­æ˜¾ç¤ºæ’ä»¶ä¿¡æ¯å’Œä½¿ç”¨å£°æ˜
def on_app_started(*args, **kwargs):
    print("=" * 60)
    print("å¤šæ¨¡æ€webuiæ’ä»¶12 - forgeç‰ˆæœ¬ä¸“ç”¨")
    print("å¼€å‘è€…ï¼šé¸¡è‚‰çˆ±åœŸè±†")
    print("ç½‘å€ï¼šhttps://space.bilibili.com/403361177")
    print("å£°æ˜ï¼šä¸ºåˆ›ä½œè€…æä¾›æ›´ä¾¿æ·æ›´å¼ºå¤§æ— å¤æ‚å·¥ä½œæµçš„æ’ä»¶")
    print()
    print("é›†æˆåŠŸèƒ½ï¼š")
    print("- å›¾åƒåˆ†å‰²")
    print("- å›¾åƒç¼–è¾‘")
    print("- å›¾åƒæ¸…ç†")
    print("- æ‰¹é‡æ ‡æ³¨")
    print("- å¤§è¯­è¨€æ¨¡å‹äº¤äº’")
    print("- æ™ºèƒ½æŠ å›¾")
    print("- è§†é¢‘æå–å…³é”®å¸§")
    print("- å…³é”®è¯è¾…åŠ©æ¨¡æ¿")
    print("- æ•°å­—äººè§†é¢‘ç”Ÿæˆ")
    print("- Qwenå›¾åƒç”Ÿæˆ")
    print()
    print("ä½¿ç”¨é¡»çŸ¥ï¼šä½¿ç”¨æ­¤æ’ä»¶è€…è¯·åˆæ³•ä½¿ç”¨AIï¼Œä¸å¾—å‘è¡¨ä¸æ­£å½“è¨€è®ºï¼Œä½œå‡æ–°é—»ï¼ŒäºŒæ¬¡é”€å”®ï¼ŒäºŒæ¬¡æ”¹è£…ç­‰è¿æ³•è¡Œä¸ºï¼Œä¹‹åçš„ä¸€åˆ‡è¡Œä¸ºä¸æ’ä»¶å¼€å‘è€…æ— å…³ã€‚")
    print("=" * 60)

script_callbacks.on_app_started(on_app_started)

# æ£€æŸ¥æ¨¡å—çŠ¶æ€
modules_status = {
    'index_tts': INDEX_TTS_AVAILABLE,
    'flux_kontext': FLUX_KONTEXT_AVAILABLE,
    'cleaner': CLEANER_AVAILABLE,
    'sam': SAM_AVAILABLE,
}
