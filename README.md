
一个为 Stable Diffusion WebUI Forge 设计的多功能集成插件，集成了图像识别、语言交互、视频处理、图像编辑等多种AI功能。

## 核心功能

- 📚 **资源汇总**: 集中管理各类资源和公告信息
- 🖼️ **图像识别与语言交互**: 支持多种视觉和语言模型，可进行图像描述、内容分析等
- ✂️ **智能抠图**: 基于 rembg 实现一键背景移除
- 🖌️ **图像分割**: 集成 Segment Anything Model (SAM) 进行精确图像分割
- 🧹 **图像清理**: 提供图像清理和修复功能
- 🎬 **视频关键帧提取**: 从视频中提取关键帧用于进一步处理
- 🤖 **数字人视频生成**: 基于 LatentSync 实现音频驱动的数字人视频生成
- 🔊 **TTS语音合成**: 集成 Index-TTS 实现高质量文本转语音
- 🌟 **FLUX.1 图像编辑**: 集成 FLUX.1-Kontext 进行上下文感知的图像编辑

## 功能模块详细介绍

### 1. 资源汇总
- 集中展示重要公告和资源信息
- 提供快速访问各类功能的入口
- 显示插件使用说明和更新日志

### 2. 图像识别与语言交互
#### 核心特性
- 支持多种视觉模型（Qwen-VL、LLaMA-Vision等）
- 支持多种语言模型（Qwen、DeepSeek等）
- 提供快捷提示词模板
- 支持单张和批量图像处理
- 根据显存大小推荐合适的模型（8GB显存推荐1.7B/3B模型，16GB显存可选latest/7B模型）

#### 模型类型
- 图像识别模型：可处理图片输入，支持单张和批量操作
- 语言交互模型：仅支持文本对话，不处理图片

#### 快捷描述功能
提供多种预设提示词模板：
- 自然语言描述文本
- Stable Diffusion提示词
- MidJourney提示词
- 分镜构图描述
- 图生视频描述
- 文生视频描述文本
- 艺术评论分析
- 产品列表描述

#### 使用说明
1. 选择模型类型（图像识别/语言交互）
2. 选择相应的视觉或语言模型
3. 选择上传方式（单张图片/批量图片）
4. 上传图片或输入文本进行交互

### 3. 图像处理工具集

#### 智能抠图
- 基于 rembg 实现高质量背景移除
- 支持透明背景和自定义背景色
- 批量处理功能
- 实时预览效果

#### 图像分割
- 集成 Segment Anything Model (SAM)
- 精确的图像分割功能
- 支持点选和框选分割方式
- 可下载分割结果

#### 图像清理
- 图像去噪和修复功能
- 简单易用的界面
- 支持多种清理模式

### 4. 视频关键帧提取
- 多种提取模式（关键帧/等间隔/场景变化）
- 可调节提取质量
- 支持多种视频格式
- 可预览提取的帧

### 5. 数字人视频生成
- 基于 LatentSync 的音频驱动视频生成
- 支持自定义推理步数和引导尺度
- 需要清晰正面人脸的视频作为输入
- 支持多种音频格式

### 6. Index-TTS语音合成
- 集成 Index-TTS 实现高质量语音合成
- 支持多种语音风格
- 可调节语速、音调等参数
- 支持中文和多语言合成

### 7. FLUX.1-Kontext图像编辑
- 上下文感知的图像编辑功能
- 支持基于文本的图像修改
- 保持图像上下文一致性

## 安装说明

### 前置要求
- Stable Diffusion WebUI Forge 环境
- Python 3.10+
- CUDA 支持（推荐）

### 安装步骤
1. 克隆本仓库到 extensions 目录：
   ```bash
   cd sd-webui-forge-aki-v4.0/extensions
   git clone https://github.com/yourusername/MultiModal-Forge.git
